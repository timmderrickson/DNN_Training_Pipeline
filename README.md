# ğŸ§  Deep Learning Training Pipeline

This project provides a modular and extensible framework for training, evaluating, and visualizing segmentation models for microscopy images using [Cellpose](https://github.com/MouseLand/cellpose) and related tools.

## ğŸš€ Features

* **Batch inference** on large microscopy datasets with support for ground truth matching, scoring, and visualization.
* **Flexible training pipeline** with automatic data preparation, augmentation, splitting, training, and metric logging.
* **Rich visualizations**: overlay outlines, masks, comparison plots, and per-class analysis.
* **Metric logging** and batch-level comparison (IoU, Dice, etc.).
* **Custom configuration** for classes, training augmentation, and model checkpointing.

---

## ğŸ“¦ Directory Structure (Key Parts)

```
DNN_Training_Pipeline/
â”œâ”€â”€ main.py                      # Entry point for training and batch run
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ helper_functions.py      # Common utility functions
â”‚   â”œâ”€â”€ model_functions.py       # Cellpose model loading, inference
â”‚   â”œâ”€â”€ scoring_functions.py     # Metric calculation, CSV export
â”‚   â”œâ”€â”€ polygon_json_visualizations.py  # Visualization for masks and comparisons
â”‚   â””â”€â”€ json_conversion_tools.py # Conversions to/from polygon JSONs
â”œâ”€â”€ training/
â”‚   â””â”€â”€ training_pipeline.py     # Functions to prepare, split, and train datasets
â”œâ”€â”€ models/                      # Saved models and checkpoints
â”œâ”€â”€ data/                        # Input images and annotation JSONs
â”œâ”€â”€ outputs/                     # Predictions, visualizations, and metrics
â”œâ”€â”€ requirements.gpu.txt         # Required packages (GPU-focused)
â””â”€â”€ README.md                    # You are here
```

---

## âš¡ Quickstart

### â–¶ï¸ Inference

```python
from main import batch_run
from models import model_functions as mf

model = mf.instantiate_cellpose_model(net="CPnetV2", gpu=True)

batch_run(
    image_inputs="data/images/",
    ground_truth_json_paths="data/annotations/",
    model_instance=model,
    diameter=30,
    compare=True,
    save_visuals=True,
    visualizations=True
)
```

### ğŸ“ Training

```python
from main import batch_train

batch_train(
    gt_json_folder="data/annotations/",
    image_folder="data/images/",
    output_image_folder="training/prepared_images/",
    output_mask_folder="training/prepared_masks/",
    image_shape=(3000, 3000),
    augmentation_config={"horizontal_flip": 0.5, "brightness_range": (0.9, 1.1)},
    num_augments=5,
    split_dir="training/split/",
    save_path="training/trained_model/",
    n_epochs=100,
    batch_size=8,
    gpu=True
)
```

---

## ğŸ“š How To Contribute

* Add clear docstrings to all new functions.
* Group utility functions in `helper_functions.py`.
* Follow the naming patterns for ground truth: `Plate_Site.json` â‡„ `Araceli_Plate_Site_*.tiff`
* Run and log training/inference through `main.py` whenever possible.

---
